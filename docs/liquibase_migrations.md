# Database Migrations - Managing structure modifications, new table creation, and data manipulation

## Overview

Insta HMS uses two databases in PostgreSQL hms* and hms*_q. 

The hms* database is primary transactional and master data database, and uses schema internally to tenant each customer or installation. For hms* database, Insta HMS leverages liquibase as database migration and version control tool.

The hms*_q database is used by the quartz job scheduler as job storage. The data is stored in **quartz** schema. As the schema is not altered and the need for data alteration is close to none, the initial structure is kept in a simple sql file instahms/WEB-INF/install/sql/quartz_tables.sql. Same can be injected directly using psql or PGAdmin tools.


## I want to use a new extension of PostgreSQL / Understanding extensions schema in hms* database

Use of database extensions are highly discouraged as they bind us to a specific database engine. In an extreme rarity, if you wish to introduce a database extension, as a convention we add extension to `extensions` schema. As PostgreSQL extensions are unique per database, if we put it in a customer schema reuse of an extension across mutiple schema in Multi schema database becomes a bottle neck.

Currently extensions are managed outside of liquibase migration. You need to add the extension in instahms/WEB-INF/install/bin/install_extensions.sh file, which is executed during upgrade and install process. 

## Liquibase based migrations - Transforming application schema and managing data manipulation

As already mentioned liquibase is used for application's primary database version control. You can learn more about liquibase at https://www.liquibase.org. The full set of migrations files for liquibase can be found in codebase under instahms/src/main/resources/migrations. In a build the files are located in WEB-INF/classes/migrations folder.

### Running liqubase migration in local development environment

Refer https://github.com/practo/insta-hms/wiki/Running-a-liquibase-update-in-local-development-environment

### Generating a new liquibase migration file

Generate empty liquibase migration file using the script generate-db-file.py(in the root directory of instahms). The script takes an argument to provide naming which is appended to the file name.

example
```
 $ python3 generate-db-file.py gen-report
```

Ensure that the newly created file contains the line `-- changeset {github-handle}:{commit-message-describing-change}`. Github handle and the commit message become part of the databasechangelog table. **The commit message must not have any spaces.**

### Managing views, functions and triggers
As most of the liquibase migrations we write deal with DDL or structural alterations of database tables, having view, fucntions and triggers affects execution of these changes. To simplify the migration run, the upgrade_schema.py script drops all views, functions and triggers before starting liquibase, and reruns all the following migrations files at the last leg of liquibase execution to restore system defined views, functions and triggers.

  * 999999999985-vft.sql
  * 999999999986-report-views.sql
  * 999999999987-accounting-views.sql
  * 999999999988-audit-log-triggers.sql
  * 999999999988-gen-report-views.sql

❗❗ **DO NOT CREATE NEW LIQUIBASE FILE FOR CREATION / ALTERATION / DELETION OF VIEWS FUNCTIONS OR TRIGGERS** ❗❗

#### Adding new views, functions and triggers

New views can be added to these files using following conventions

*999999999985-vft.sql* - All general views, functions and triggers that are used by application.

*999999999986-report-views.sql* - Views specifically used by reports

*999999999987-accounting-views.sql* - Legacy Financial Accounting related views, will be eventually deprecated, currently 60% functionality migrated to FA framework in application which leverages raw querying using Hibernate.

*999999999988-audit-log-triggers.sql* - Only trigger definitions related to generation of audit logs (follow the trigger convention by refering comments in the file)

❗❗ *999999999988-gen-report-views.sql* - Do not alter this file as it is autogenerated during each build. Essentially contains compiled view for SRJS files. This is used to detect and resultant malformed queries from SRJS during development ❗❗

#### Altering view, functions and triggers

Find the related view / trigger / function in the above files and alter the definition.

#### Deleting view, functions and triggers

Find the related view / trigger / function in the above files and remove both DROP and CREATE statements

### Creating or altering a column to store amount/currency data type

If introducing or altering a column that stores currency data type understand and follow the precision 2 and precision 3 support conventions

#### Datatypes to use for Amount Fields

Precision-2 : numeric(15,2)

Precision-3 : numeric(16,3)

#### What is Precision-2 Support?
Precision-2 support in our terminology stands for supporting 2 decimal digits precision for database fields which store value of type amount. This is commonly used by our customers in India, and ROW except some countries in MEA.

#### What is Precision-3 Support?
Precision-3 support in our terminology stands for supporting 3 decimal digits precision for database fields which store value of type amount. 

#### Why Precision-3 Support?
Unlike currencies we are commonly used to (INR, USD, EUR, and others) which use 100 minor units, there are currencies (BHD, IQD, JOD, KWD, LYD, OMR, TND) which are divided into 1000 minor units. 3 digit precision is enabled for customers who use Insta HMS in these countries. 

#### Why 15 digits and not 10 digits in amount fields?
There are currencies like JPY, IDR, VND which are valued so low that minor units are not used in day to day activities and denominations < 1000 are issue by central banks of these countries as coins & banknotes are common for 10K to 50K. Hence we also support for amount values upto 13 digits to handle such amounts in such geographies.

#### handling precision-2 and precision-3 support in application

If introducing amount field, you also need to create a migration from precision-3 for this field in a separate migration file. Template for precision 3 migration can be found in this commit https://github.com/practo/insta-hms/commit/1ecc58447e79367923a9787ead805fc2c8557437. Notice that precision3 migration is set of alter statements changing datatype to numeric(16,3). Ensure that changeset comment on line 2 follows with *context:precision-3*. This is to instruct liquibase to only execute if context is precision3. Also line 3 through 5 are to be retained. 

If the new databasechange is specific for precision-3 schemas; then tag the changeset with `context:precision-3`. So the changeset line(the second line in the migration) must look like:
`-- changeset <author-name>:<message-describing-changeset> context:precision-3`.
Please refer to 201807261659-precision-3.sql in case of confusion!

Ensure execution order of liquibase migration is PRECISION2 MIGRATION -> PRECISION3 MIGRATION -> DATA MIGRATIONS (IF ANY). Not following this order may result in bad data migration causing loss of 3rd decimal digit.

### Introducing new table and sequence

If you are introducing a new table and related sequences, ensure to add a comment to the table and sequence. This is required as during golive of a new customer, conversion of training schema to production schema is performed. during this phase the transactional data (which was added for testing and training purposes in training schema) is truncated and sequences are resetted to 1. To ensure the [golive script in allspark](https://github.com/practo/insta-allspark/blob/master/ansible/playbooks/roles/copy_schema/files/transaction_cleanup.py) does not truncate master or settings table, you need to mark each new table and sequence as transaction or master as part of comments. The comment is essentially a stringified json object. To ensure the json object is created properly as part of comment we have a databse helper function `comment_on_table_or_sequence_if_exists(relationName TEXT, isTable BOOLEAN, type TEXT, comment TEXT)` that can be used to set the comments

Below is an example of statements that needs to be added for a master data or settings table, for a reference migration check this [file](https://github.com/practo/insta-hms/blob/develop/instahms/src/main/resources/migrations/201911071721-create-table-ohsrsdohgovph-meta-data.sql):

```sql
SELECT comment_on_table_or_sequence_if_exists('ohsrsdohgovph_meta_data',true, 'Master','ohsrs.doh.gov.ph meta data');
SELECT comment_on_table_or_sequence_if_exists('ohsrsdohgovph_meta_data_id_seq', false, 'Master','');
```

For a transaction data tables below is an example. For a reference migration check this [file](https://github.com/practo/insta-hms/blob/develop/instahms/src/main/resources/migrations/201911071722-create-table-ohsrsdohgovph-report-csv-upload.sql):

```sql
SELECT comment_on_table_or_sequence_if_exists('ohsrsdohgovph_report_csv_upload',true, 'Txn','ohsrs.doh.gov.ph uploaded data');
SELECT comment_on_table_or_sequence_if_exists('ohsrsdohgovph_report_csv_upload_id_seq', false, 'Txn','');
```

### Dos and Don'ts of writing migrations

* Create a seperate migration file for DDLs and data migrations. In other words, keep CREATE , ALTER, DROP statements separate from INSERT, UPDATE, DELETE.

* There are tools in Travis CI which checks and blocks PR if someone introduces a liquibase migration with numeric datatype. insta-gitbot will place a automated review for further manual intervention. This check is in place to ensure if the numeric datatype column is actually used for amount, related precision-3 migration is in place. Code reviewers are advised to thoroughly check the PR before approving. Refer this PR for example https://github.com/practo/insta-hms/pull/7986#pullrequestreview-175192628

* We also have automated checks in Travis CI to detect missing comments on tables and sequences. insta-gitbot will place a automated review and block the PR unless all tables and seqences have comments updated and meeting convention.

* Never alter an existing Liquibase migration (Exceptions 9999999999* series migration files that manage views, triggers and function creation and are rerun during each liqubase run)

* You can put `failOnError:false` tag next to migration comments for certain migrations where you would like to instruct liquibase not to fail if the particular liqibase migration throws error. Be cautious while using this tag as using same can lead to database structure becoming inconsistent. Also it is a good practice to keep single SQL statement per migration when using this tag, to avoid cases where rest of the statements which were suppose to execute did not execute as the previous statement failed. Good use cases for use of this tag are 

    - Introduction of an Index that for some customer were directly created on production database to overcome a query performance issue. 

    - Insertion of a data to a table, where unique constraint may likely fail, again due to existing data.
